# PySpark DataFrame Operations — Complete Notes

---

## Overview

This document explains important **PySpark DataFrame operations** used in real data engineering and analytics work.
All examples are based on practical scenarios and written in simple language so that beginners can understand clearly.

Covered Topics:

* Type Casting
* Sorting (Multiple Scenarios)
* Limit
* Drop Columns
* Drop Duplicates
* Distinct
* Union vs Union By Name
* String Functions
* Date Functions

---

# Type Casting

### Code

```python
df = df.withColumn('Item_Weight', col('Item_Weight').cast(StringType()))
```

### What this means

**Type Casting** means converting the data type of a column from one type to another.

Here:

* `Item_Weight` was probably numeric earlier
* Now it is converted into **String**

### Why we do this

* To perform string operations
* To match schema while joining or union
* To fix wrong data types

### Check Schema

```python
df.printSchema()
```

This shows:

* Column names
* Data types
* Nullable or not

---

# Sorting

Sorting means arranging data either:

* Ascending (small → big)
* Descending (big → small)

---

## Scenario 1

```python
df.sort(col('Item_Weight').desc()).display()
```

### Explanation

* Sorts based on **Item_Weight**
* Highest value first

---

## Scenario 2

```python
df.sort(col('Item_Visibility').asc()).display()
```

### Explanation

* Sorts based on **Item_Visibility**
* Lowest value first

---

## Scenario 3

```python
df.sort(['Item_Weight','Item_Visibility'],ascending = [0,0]).display()
```

### Explanation

Sorting using **multiple columns**.

Order:

1. First sorted by `Item_Weight` (Descending)
2. Then sorted by `Item_Visibility` (Descending)

`0` means Descending.

---

## Scenario 4

```python
df.sort(['Item_weight','Item_Visibility'], ascending = [0,1]).display()
```

### Explanation

* First column sorted Descending
* Second column sorted Ascending

`0` → Descending
`1` → Ascending

---

# Limit

### Code

```python
df.limit(10).display()
```

### Explanation

Returns only the **first 10 rows**.

### Why we use

* Quick preview
* Avoid loading full data
* Useful in big data

---

# DROP

Used to remove columns from DataFrame.

---

## Scenario 1

```python
df.drop('Item_Visibility').display()
```

Removes only one column.

---

## Scenario 2

```python
df.drop('Item_Visibility','Item_Type').display()
```

Removes multiple columns.

---

# Drop Duplicates

Removes repeated rows.

---

## Scenario 1

```python
df.dropDuplicates().display()
```

Removes rows that are completely identical.

---

## Scenario 2

```python
df.drop_duplicates(subset=['Item_Type']).display()
```

Removes duplicates based on only **Item_Type** column.

Means:

* If multiple rows have same Item_Type
* Only one will be kept

---

# Distinct

```python
df.distinct().display()
```

### Explanation

* Returns unique rows
* Same as dropDuplicates without subset

---

# UNION and UNION BY NAME

Used to combine two DataFrames.

---

## Preparing DataFrames

```python
data1 = [('1','kad'),
        ('2','sid')]
schema1 = 'id STRING, name STRING'

df1 = spark.createDataFrame(data1,schema1)


data2 = [('3','rahul'),
        ('4','jas')]
schema2 = 'id STRING, name STRING'

df2 = spark.createDataFrame(data2,schema2)
```

```python
df1.display()
```

```python
df2.display()
```

---

## UNION

```python
df1.union(df2).display()
```

### Important Rule

* Column **order must be same**
* Column names do not matter

---

## Different Column Order Example

```python
data1 = [('kad','1',),
        ('sid','2',)]
schema1 = 'name STRING, id STRING'

df1 = spark.createDataFrame(data1,schema1)


df1.display()
```

```python
df1.union(df2).display()
```

### Problem

Data will be mismatched because:

* Order is different

---

## UNION BY NAME

```python
df1.unionByName(df2).display()
```

### Advantage

* Matches columns using **column names**
* Order does not matter

---

# String Functions

## Initcap / Upper

```python
df.select(upper('Item_Type').alias('upper_Item_Type')).display()
```

### Explanation

* Converts text into **UPPERCASE**
* Useful for cleaning data
* Helps in standardization

---

# Date Functions

Date functions are heavily used in:

* Data Engineering
* ETL Pipelines
* Reporting

---

## Current Date

```python
df = df.withColumn('curr_date',current_date())

df.display()
```

Adds today's date column.

---

## Date Add

```python
df = df.withColumn('week_after',date_add('curr_date',7))

df.display()
```

Adds 7 days to current date.

---

## Date Sub

```python
df.withColumn('week_before',date_sub('curr_date',7)).display()
```

Subtracts 7 days.

---

### Alternative Way

```python
df = df.withColumn('week_before',date_add('curr_date',-7))

df.display()
```

Same result using negative value.

---

## DateDiff

```python
df = df.withColumn('datediff',datediff('week_after','curr_date'))

df.display()
```

### Explanation

* Finds difference between two dates
* Output in number of days

---

## Date Format

```python
df = df.withColumn('week_before',date_format('week_before','dd-MM-yyyy'))

df.display()
```

### Explanation

Changes date display format.

Example:

* `2026-02-10` → `10-02-2026`

---

# Summary Table

| Topic            | Purpose              | Key Point                               |
| ---------------- | -------------------- | --------------------------------------- |
| Type Casting     | Change data type     | Helps in operations and schema matching |
| Sort             | Arrange rows         | Ascending / Descending                  |
| Limit            | Show few rows        | Preview data                            |
| Drop             | Remove columns       | Clean dataset                           |
| DropDuplicates   | Remove repeated rows | Can use subset                          |
| Distinct         | Unique rows          | Same as full duplicate removal          |
| Union            | Combine DataFrames   | Column order must match                 |
| UnionByName      | Combine safely       | Matches using column names              |
| String Functions | Clean text           | Standardization                         |
| Date Functions   | Work with dates      | Used in ETL and reporting               |

---

**End of Notes**
