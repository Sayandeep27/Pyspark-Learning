# Window Functions in PySpark

## ROW_NUMBER(), RANK() vs DENSE_RANK()

---

## What are Window Functions?

**Window Functions** are used when we want to perform calculations across a set of rows that are related to the current row.

Instead of grouping rows into a single output (like `groupBy`), window functions **retain all rows** and add a new calculated column.

In simple words:

> Window functions help us **compare rows with other rows** without losing original data.

---

## Why Do We Use Window Functions?

Common use cases:

* Ranking products
* Finding top N records
* Removing duplicates
* Sequential numbering
* Department-wise ranking
* Latest record selection

---

## Basic Syntax

```python
from pyspark.sql.window import Window
from pyspark.sql.functions import row_number, rank, dense_rank

windowSpec = Window.orderBy("ColumnName")
```

With partition:

```python
windowSpec = Window.partitionBy("Category").orderBy("Sales")
```

---

# ROW_NUMBER()

## What is ROW_NUMBER()?

`ROW_NUMBER()` assigns a **unique sequential number** to each row.

Even if values are the same, numbering will **not repeat**.

---

## Example Dataset

| Product | Sales |
| ------- | ----- |
| A       | 100   |
| B       | 100   |
| C       | 90    |
| D       | 80    |

---

## Code Example

```python
from pyspark.sql.window import Window
from pyspark.sql.functions import row_number

windowSpec = Window.orderBy("Sales")

df.withColumn("row_num", row_number().over(windowSpec)).show()
```

---

## Output

| Product | Sales | Row_Number |
| ------- | ----- | ---------- |
| D       | 80    | 1          |
| C       | 90    | 2          |
| A       | 100   | 3          |
| B       | 100   | 4          |

---

## Key Point

* Numbers are **always unique**
* Duplicate values still get different numbers

---

# RANK()

## What is RANK()?

`RANK()` assigns rank based on ordering.

If duplicate values exist:

* Same rank is assigned
* **Next rank is skipped**

---

## Example Dataset

| Product | Sales |
| ------- | ----- |
| A       | 100   |
| B       | 100   |
| C       | 90    |
| D       | 80    |

---

## Code Example

```python
from pyspark.sql.functions import rank

windowSpec = Window.orderBy(df.Sales.desc())

df.withColumn("rank", rank().over(windowSpec)).show()
```

---

## Output

| Product | Sales | Rank |
| ------- | ----- | ---- |
| A       | 100   | 1    |
| B       | 100   | 1    |
| C       | 90    | 3    |
| D       | 80    | 4    |

---

## Key Point

* Same values → Same rank
* Rank **skips numbers** after duplicates

---

# DENSE_RANK()

## What is DENSE_RANK()?

`DENSE_RANK()` is similar to `RANK()` but **does not skip numbers**.

---

## Example Dataset

| Product | Sales |
| ------- | ----- |
| A       | 100   |
| B       | 100   |
| C       | 90    |
| D       | 80    |

---

## Code Example

```python
from pyspark.sql.functions import dense_rank

windowSpec = Window.orderBy(df.Sales.desc())

df.withColumn("dense_rank", dense_rank().over(windowSpec)).show()
```

---

## Output

| Product | Sales | Dense_Rank |
| ------- | ----- | ---------- |
| A       | 100   | 1          |
| B       | 100   | 1          |
| C       | 90    | 2          |
| D       | 80    | 3          |

---

## Key Point

* Same values → Same rank
* **No rank is skipped**

---

# RANK vs DENSE_RANK vs ROW_NUMBER

## Quick Comparison Table

| Feature          | ROW_NUMBER        | RANK      | DENSE_RANK |
| ---------------- | ----------------- | --------- | ---------- |
| Duplicate values | Allowed           | Allowed   | Allowed    |
| Same value rank  | Different numbers | Same rank | Same rank  |
| Rank skipping    | No                | Yes       | No         |
| Unique numbering | Yes               | No        | No         |

---

## Easy Real-Life Example

Imagine a class test with marks:

| Student | Marks |
| ------- | ----- |
| Rahul   | 95    |
| Aman    | 95    |
| Neha    | 90    |

### Using ROW_NUMBER

Rahul → 1
Aman → 2
Neha → 3

### Using RANK

Rahul → 1
Aman → 1
Neha → 3 (2 is skipped)

### Using DENSE_RANK

Rahul → 1
Aman → 1
Neha → 2 (No skip)

---

# When Should You Use What?

## Use ROW_NUMBER When

* You need unique numbering
* Removing duplicates
* Selecting latest record

## Use RANK When

* Competition ranking (like sports)
* Rank gaps are acceptable

## Use DENSE_RANK When

* Continuous ranking required
* Leaderboards
* Department-wise performance ranking

---

# With Partition Example

```python
from pyspark.sql.window import Window
from pyspark.sql.functions import row_number

windowSpec = Window.partitionBy("Department").orderBy("Salary")

df.withColumn("row_num", row_number().over(windowSpec)).show()
```

---

## What Happens Here?

* Each department gets its own numbering
* Counting restarts for every partition

---

# Interview Tips

* Window functions **do not reduce rows**
* `groupBy` reduces rows
* Ranking functions are very commonly asked in interviews
* Difference between `RANK` and `DENSE_RANK` is a favorite question

---

# One Line Summary

* **ROW_NUMBER** → Unique numbering
* **RANK** → Same rank but skips numbers
* **DENSE_RANK** → Same rank, no skipping
